#!/usr/bin/env python
"""
ğŸ” ç³»ç»Ÿå°±ç»ªéªŒè¯è„šæœ¬
==================

æ£€æŸ¥æ‰€æœ‰å¿…è¦ç»„ä»¶æ˜¯å¦å°±ç»ªï¼Œç¡®ä¿èƒ½å¤Ÿç«‹å³å“åº”ç›²æµ‹ã€‚
"""

import sys
from pathlib import Path
import subprocess

def print_header(text):
    """æ‰“å°æ ‡é¢˜"""
    print("\n" + "=" * 80)
    print(f"  {text}")
    print("=" * 80)

def check_python_version():
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    print("\nğŸ“‹ æ£€æŸ¥Pythonç‰ˆæœ¬...")
    version = sys.version_info
    if version.major == 3 and version.minor >= 11:
        print(f"   âœ… Python {version.major}.{version.minor}.{version.micro}")
        return True
    else:
        print(f"   âŒ Pythonç‰ˆæœ¬è¿‡ä½: {version.major}.{version.minor}.{version.micro}")
        print(f"      éœ€è¦ Python 3.11+")
        return False

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…"""
    print("\nğŸ“¦ æ£€æŸ¥ä¾èµ–åŒ…...")
    packages = {
        'torch': 'PyTorch',
        'numpy': 'NumPy',
        'pandas': 'Pandas',
        'matplotlib': 'Matplotlib',
        'scipy': 'SciPy',
        'yaml': 'PyYAML'
    }

    all_ok = True
    for module, name in packages.items():
        try:
            __import__(module)
            print(f"   âœ… {name}")
        except ImportError:
            print(f"   âŒ {name} æœªå®‰è£…")
            all_ok = False

    return all_ok

def check_cuda():
    """æ£€æŸ¥CUDAå¯ç”¨æ€§"""
    print("\nğŸ® æ£€æŸ¥GPU/CUDA...")
    try:
        import torch
        if torch.cuda.is_available():
            print(f"   âœ… CUDAå¯ç”¨")
            print(f"   âœ… GPUæ•°é‡: {torch.cuda.device_count()}")
            print(f"   âœ… GPUåç§°: {torch.cuda.get_device_name(0)}")
            return True
        else:
            print(f"   âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨ç†ï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
            return True  # CPUä¹Ÿå¯ä»¥å·¥ä½œï¼Œåªæ˜¯æ…¢ä¸€äº›
    except Exception as e:
        print(f"   âŒ æ£€æŸ¥CUDAæ—¶å‡ºé”™: {e}")
        return False

def check_model_weights():
    """æ£€æŸ¥æ¨¡å‹æƒé‡æ–‡ä»¶"""
    print("\nğŸ§  æ£€æŸ¥æ¨¡å‹æƒé‡...")
    checkpoint_dir = Path('checkpoints/day2_fast_training')

    if not checkpoint_dir.exists():
        print(f"   âŒ æ£€æŸ¥ç‚¹ç›®å½•ä¸å­˜åœ¨: {checkpoint_dir}")
        return False

    best_models = list(checkpoint_dir.glob('best_*.pth'))
    if not best_models:
        print(f"   âŒ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹æ–‡ä»¶")
        return False

    best_model = max(best_models, key=lambda p: p.stat().st_mtime)
    size_mb = best_model.stat().st_size / (1024 * 1024)

    print(f"   âœ… æ‰¾åˆ°æ¨¡å‹: {best_model.name}")
    print(f"   âœ… æ–‡ä»¶å¤§å°: {size_mb:.2f} MB")

    if size_mb < 1:
        print(f"   âš ï¸  è­¦å‘Š: æ¨¡å‹æ–‡ä»¶å¯èƒ½ä¸å®Œæ•´ï¼ˆå°äº1MBï¼‰")
        return False

    return True

def check_config_files():
    """æ£€æŸ¥é…ç½®æ–‡ä»¶"""
    print("\nâš™ï¸  æ£€æŸ¥é…ç½®æ–‡ä»¶...")
    config_file = Path('config/day2_fast_training.yaml')

    if not config_file.exists():
        print(f"   âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return False

    print(f"   âœ… é…ç½®æ–‡ä»¶å­˜åœ¨: {config_file}")
    return True

def check_inference_script():
    """æ£€æŸ¥æ¨ç†è„šæœ¬"""
    print("\nğŸ”® æ£€æŸ¥æ¨ç†è„šæœ¬...")
    script = Path('predict_new_data.py')

    if not script.exists():
        print(f"   âŒ æ¨ç†è„šæœ¬ä¸å­˜åœ¨: {script}")
        return False

    print(f"   âœ… æ¨ç†è„šæœ¬å­˜åœ¨: {script}")

    # æ£€æŸ¥è„šæœ¬å¤§å°ï¼ˆç¡®ä¿ä¸æ˜¯ç©ºæ–‡ä»¶ï¼‰
    size_kb = script.stat().st_size / 1024
    if size_kb < 1:
        print(f"   âŒ æ¨ç†è„šæœ¬æ–‡ä»¶è¿‡å°ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰")
        return False

    print(f"   âœ… è„šæœ¬å¤§å°: {size_kb:.2f} KB")
    return True

def check_output_directory():
    """æ£€æŸ¥è¾“å‡ºç›®å½•"""
    print("\nğŸ“ æ£€æŸ¥è¾“å‡ºç›®å½•...")
    output_dir = Path('outputs')

    if not output_dir.exists():
        print(f"   âš ï¸  è¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œå°†è‡ªåŠ¨åˆ›å»º")
        output_dir.mkdir(parents=True, exist_ok=True)

    print(f"   âœ… è¾“å‡ºç›®å½•å°±ç»ª")
    return True

def check_delivery_package():
    """æ£€æŸ¥äº¤ä»˜åŒ…"""
    print("\nğŸ“¦ æ£€æŸ¥äº¤ä»˜åŒ…...")
    delivery_dir = Path('Delivery_Package')

    if not delivery_dir.exists():
        print(f"   âš ï¸  äº¤ä»˜åŒ…ç›®å½•ä¸å­˜åœ¨")
        return False

    required_files = [
        'README.md',
        'QUICK_START.md',
        'DEPLOYMENT_GUIDE.md',
        'requirements.txt',
        'predict_new_data.py'
    ]

    all_ok = True
    for file in required_files:
        file_path = delivery_dir / file
        if file_path.exists():
            print(f"   âœ… {file}")
        else:
            print(f"   âŒ ç¼ºå°‘: {file}")
            all_ok = False

    return all_ok

def run_quick_test():
    """è¿è¡Œå¿«é€Ÿæµ‹è¯•"""
    print("\nğŸ§ª è¿è¡Œå¿«é€Ÿæµ‹è¯•...")
    try:
        from config.config import Config
        from model.enhanced_deeponet import SingleBranchDeepONet
        import torch

        print(f"   âœ… é…ç½®åŠ è½½å™¨å¯¼å…¥æˆåŠŸ")
        print(f"   âœ… æ¨¡å‹å®šä¹‰å¯¼å…¥æˆåŠŸ")

        # å°è¯•åŠ è½½é…ç½®
        cfg = Config(config_file='config/day2_fast_training.yaml')
        print(f"   âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")

        # å°è¯•åˆå§‹åŒ–æ¨¡å‹
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = SingleBranchDeepONet(cfg).to(device)
        print(f"   âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")

        return True
    except Exception as e:
        print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print_header("ğŸ” ç³»ç»Ÿå°±ç»ªéªŒè¯ - ç›²æµ‹å‡†å¤‡æ£€æŸ¥")

    checks = [
        ("Pythonç‰ˆæœ¬", check_python_version),
        ("ä¾èµ–åŒ…", check_dependencies),
        ("GPU/CUDA", check_cuda),
        ("æ¨¡å‹æƒé‡", check_model_weights),
        ("é…ç½®æ–‡ä»¶", check_config_files),
        ("æ¨ç†è„šæœ¬", check_inference_script),
        ("è¾“å‡ºç›®å½•", check_output_directory),
        ("äº¤ä»˜åŒ…", check_delivery_package),
        ("å¿«é€Ÿæµ‹è¯•", run_quick_test)
    ]

    results = []
    for name, check_func in checks:
        try:
            result = check_func()
            results.append((name, result))
        except Exception as e:
            print(f"\n   âŒ æ£€æŸ¥ '{name}' æ—¶å‡ºé”™: {e}")
            results.append((name, False))

    # æ‰“å°æ€»ç»“
    print_header("ğŸ“Š æ£€æŸ¥ç»“æœæ±‡æ€»")
    all_passed = True
    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {status:12} | {name}")
        if not result:
            all_passed = False

    print("\n" + "=" * 80)
    if all_passed:
        print("ğŸ‰ æ­å–œï¼æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Œç³»ç»Ÿå·²å°±ç»ªï¼")
        print("=" * 80)
        print("\nâš¡ ä¸‹ä¸€æ­¥ï¼š")
        print("   1. ç­‰å¾…å®¢æˆ·å‘é€ç›²æµ‹CSVæ–‡ä»¶")
        print("   2. å°†CSVæ–‡ä»¶æ”¾å…¥ä»»æ„ç›®å½•")
        print("   3. è¿è¡Œ: python predict_new_data.py --input_dir /path/to/csv")
        print("   4. 30åˆ†é’Ÿå†…æŸ¥çœ‹ outputs/blind_test/ ç›®å½•è·å–ç»“æœ")
        print("\nğŸš€ å‡†å¤‡å®Œæ¯•ï¼Œéšæ—¶åº”å¯¹ç›²æµ‹æŒ‘æˆ˜ï¼")
        return 0
    else:
        print("âŒ éƒ¨åˆ†æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·ä¿®å¤ä¸Šè¿°é—®é¢˜")
        print("=" * 80)
        print("\nğŸ’¡ å»ºè®®ï¼š")
        print("   1. æ£€æŸ¥ requirements.txt ä¸­çš„ä¾èµ–æ˜¯å¦å®Œæ•´å®‰è£…")
        print("   2. ç¡®è®¤æ¨¡å‹æƒé‡æ–‡ä»¶å­˜åœ¨ä¸”å®Œæ•´")
        print("   3. è¿è¡Œ: pip install -r requirements.txt")
        return 1

if __name__ == "__main__":
    sys.exit(main())
