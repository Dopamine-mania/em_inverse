"""
DeepONetç”µç£åœºæ•°æ®åŠ è½½å™¨
å®ç°å›ºå®šæ¢é’ˆæ•°é‡çš„æ©ç DeepONetæ•°æ®æ ¼å¼è½¬æ¢
"""

import numpy as np
import pandas as pd
import torch
from pathlib import Path
from typing import List, Tuple, Dict, Any, Optional, Generator
import random
from scipy.spatial import ConvexHull

from config import Config


class MaskedDeepONetDataset:
    """æ©ç DeepONetæ•°æ®é›†ç±»"""

    def __init__(self, cfg: Config):
        self.cfg = cfg
        self.current_mask = None  # å­˜å‚¨å½“å‰batchçš„mask
        self.probe_count = cfg.data.num_probes  # ä½¿ç”¨dataé…ç½®ä¸­çš„æ¢é’ˆæ•°é‡
        self.fixed_probe_positions = cfg.data.fixed_probe_positions  # æ˜¯å¦å›ºå®šæ¢é’ˆä½ç½®
        self.fixed_probe_cache = {}  # ç¼“å­˜å›ºå®šçš„æ¢é’ˆä½ç½®ï¼ŒæŒ‰æ–‡ä»¶å­˜å‚¨

        # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        print(f"ğŸ”§ æ¢é’ˆé…ç½®:")
        print(f"   æ¢é’ˆæ•°é‡: {self.probe_count}")
        print(f"   å›ºå®šæ¢é’ˆä½ç½®: {'å¯ç”¨' if self.fixed_probe_positions else 'ç¦ç”¨'}")

    def _create_single_branch_input(self, probe_coords: np.ndarray,
                                     probe_real: np.ndarray,
                                     probe_imag: np.ndarray,
                                     frequency: float) -> np.ndarray:
        """
        ç”Ÿæˆå•Branchäº¤é”™æ ¼å¼è¾“å…¥: [x1, y1, real1, imag1, x2, y2, real2, imag2, ..., freq]

        Args:
            probe_coords: [num_probes, 2] æ¢é’ˆåæ ‡ (x, y)
            probe_real: [num_probes] å®éƒ¨æµ‹é‡å€¼
            probe_imag: [num_probes] è™šéƒ¨æµ‹é‡å€¼
            frequency: æ ‡é‡é¢‘ç‡å€¼

        Returns:
            branch_input: [num_probes * 4 + 1] å•Branchè¾“å…¥å‘é‡
        """
        branch_input = []
        for i in range(len(probe_coords)):
            branch_input.extend([
                probe_coords[i, 0],  # xåæ ‡
                probe_coords[i, 1],  # yåæ ‡
                probe_real[i],       # å®éƒ¨
                probe_imag[i]        # è™šéƒ¨
            ])
        branch_input.append(frequency)  # é¢‘ç‡æ”¾åœ¨æœ€å
        return np.array(branch_input, dtype=np.float32)

    def peek_frequency(self, csv_file: str) -> Optional[float]:
        """è½»é‡çº§é¢‘ç‡æ£€æµ‹ï¼Œè¯»å–ç¬¬ä¸€è¡Œçš„é¢‘ç‡ä¿¡æ¯"""
        try:
            # å…ˆè¯»å–ç¬¬ä¸€è¡Œçœ‹æ˜¯å¦æœ‰æ³¨é‡Š
            with open(csv_file, 'r') as f:
                first_line = f.readline().strip()

            if first_line.startswith('#'):
                # è·³è¿‡æ³¨é‡Šè¡Œï¼Œè¯»å–æ•°æ®è¡Œ
                df = pd.read_csv(csv_file, skiprows=1, nrows=1)
            else:
                # ç›´æ¥è¯»å–æ•°æ®è¡Œ
                df = pd.read_csv(csv_file, nrows=1)

            # æŸ¥æ‰¾é¢‘ç‡åˆ— (freq_1, freq_2, etc.)
            freq_columns = [col for col in df.columns if col.startswith('freq_')]

            if freq_columns:
                # è¯»å–é¢‘ç‡å€¼
                freq_value = df[freq_columns[0]].iloc[0]
                return float(freq_value)
            else:
                print(f"è­¦å‘Šï¼šæ–‡ä»¶ {csv_file} ä¸­æœªæ‰¾åˆ°é¢‘ç‡åˆ—ï¼Œå¯ç”¨åˆ—: {df.columns.tolist()}")
                return None

        except Exception as e:
            print(f"è­¦å‘Šï¼šæ— æ³•è¯»å–æ–‡ä»¶ {csv_file} çš„é¢‘ç‡ä¿¡æ¯: {e}")
            return None

    def peek_frequencies(self, csv_file: str) -> List[float]:
        """è½»é‡çº§é¢‘ç‡æ£€æµ‹ï¼Œè¯»å–æ–‡ä»¶ä¸­çš„æ‰€æœ‰é¢‘ç‡ä¿¡æ¯"""
        try:
            # å…ˆè¯»å–ç¬¬ä¸€è¡Œçœ‹æ˜¯å¦æœ‰æ³¨é‡Š
            with open(csv_file, 'r') as f:
                first_line = f.readline().strip()

            if first_line.startswith('#'):
                # è·³è¿‡æ³¨é‡Šè¡Œï¼Œè¯»å–æ•°æ®è¡Œ
                df = pd.read_csv(csv_file, skiprows=1, nrows=1)
            else:
                df = pd.read_csv(csv_file, nrows=1)

            # æŸ¥æ‰¾æ‰€æœ‰é¢‘ç‡åˆ—
            freq_columns = [col for col in df.columns if col.startswith('freq_')]
            if freq_columns:
                frequencies = []
                for freq_col in freq_columns:
                    freq_val = df[freq_col].iloc[0]
                    if pd.notna(freq_val):  # ç¡®ä¿é¢‘ç‡å€¼ä¸æ˜¯NaN
                        frequencies.append(float(freq_val))
                return frequencies
            else:
                print(f"è­¦å‘Šï¼šæ–‡ä»¶ {csv_file} ä¸­æœªæ‰¾åˆ°é¢‘ç‡åˆ—ï¼Œå¯ç”¨åˆ—: {df.columns.tolist()}")
                return []

        except Exception as e:
            print(f"è­¦å‘Šï¼šæ— æ³•è¯»å–æ–‡ä»¶ {csv_file} çš„é¢‘ç‡ä¿¡æ¯: {e}")
            return []

    def scan_available_samples(self, data_path: str, max_frequency: float = 20.0,
                             max_samples: int = 800) -> List[Dict[str, Any]]:
        """æ‰«ææ‰€æœ‰å¯ç”¨æ„å‹ï¼ˆçœŸå®æ„å‹ï¼Œä¸é¢„åˆ›å»ºå¤šä¸ªæ ·æœ¬ï¼‰
        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            max_frequency: æœ€å¤§é¢‘ç‡é™åˆ¶
            max_samples: æœ€å¤§æ ·æœ¬æ•°
        """
        valid_samples = []
        data_path = Path(data_path)

        if not data_path.exists():
            print(f"æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {data_path}")
            return []

        csv_files = list(data_path.glob("*.csv"))
        print(f"å‘ç° {len(csv_files)} ä¸ªCSVæ–‡ä»¶ï¼Œæ­£åœ¨æå–æ„å‹...")

        for csv_file in csv_files:
            # è·å–æ–‡ä»¶ä¸­çš„æ‰€æœ‰é¢‘ç‡
            frequencies = self.peek_frequencies(str(csv_file))
            if frequencies:
                file_size = csv_file.stat().st_size

                # ä¸ºæ¯ä¸ªé¢‘ç‡åˆ›å»ºä¸€ä¸ªæ„å‹æ ·æœ¬ï¼ˆä¸é¢„åˆ›å»ºå¤šä¸ªæ¢é’ˆé€‰æ‹©ï¼‰
                for freq_idx, frequency in enumerate(frequencies):
                    valid_samples.append({
                        'file': str(csv_file),
                        'frequency': frequency,
                        'freq_idx': freq_idx,
                        'size': file_size,
                        'source_file': csv_file.name
                    })

                    # å¦‚æœè®¾ç½®äº†æœ€å¤§æ ·æœ¬æ•°é™åˆ¶ä¸”å·²è¾¾åˆ°ï¼Œåˆ™åœæ­¢æ‰«æ
                    if max_samples is not None and len(valid_samples) >= max_samples:
                        print(f"è¾¾åˆ°æœ€å¤§æ ·æœ¬æ•°é™åˆ¶ ({max_samples})ï¼Œåœæ­¢æ‰«æ")
                        break
                else:
                    # å¦‚æœå†…å±‚å¾ªç¯æ²¡æœ‰è¢«breakï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶
                    continue
                # å¦‚æœå†…å±‚å¾ªç¯è¢«breakï¼Œè·³å‡ºå¤–å±‚å¾ªç¯
                break
            else:
                print(f"è­¦å‘Šï¼šæ–‡ä»¶ {csv_file.name} ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆé¢‘ç‡")

        print(f"æ€»å…±å‘ç° {len(valid_samples)} ä¸ªçœŸå®æ„å‹ï¼ˆä¸åŒé¢‘ç‡çš„ç”µç£åœºåˆ†å¸ƒï¼‰")
        return valid_samples

    def prepare_single_sample(self, csv_file: str, freq_idx: int = 0, sample_idx: int = 0) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """å°†å•ä¸ªæ„å‹è½¬æ¢ä¸ºDeepONetåŒåˆ†æ”¯æ ¼å¼ï¼šå…ˆé€‰æ¢é’ˆï¼Œå†åŸºäºæ¢é’ˆæ„å»ºå‡¸è¾¹ç•Œ
        Args:
            csv_file: CSVæ–‡ä»¶è·¯å¾„
            freq_idx: é¢‘ç‡ç´¢å¼•
            sample_idx: æ ·æœ¬ç´¢å¼•ï¼Œç”¨äºç”Ÿæˆä¸åŒçš„æ¢é’ˆé€‰æ‹©
        Returns:
            branch_real_input: å®éƒ¨æ¢é’ˆè¾“å…¥ [æ¢é’ˆæ•°, 4] = (x, y, z, frequency)
            branch_imag_input: è™šéƒ¨æ¢é’ˆè¾“å…¥ [æ¢é’ˆæ•°, 4] = (x, y, z, frequency)
            trunk_input: åæ ‡è¾“å…¥ [å†…ç‚¹æ•°, 3] = (x, y, frequency)
            target_output: ç›®æ ‡åœºå€¼ [å†…ç‚¹æ•°, 2] = (real, imag)
            probe_mask: æ¢é’ˆä½ç½®æ©ç  [å†…ç‚¹æ•°]
        """
        # è¯»å–CSVæ–‡ä»¶ï¼Œè·³è¿‡æ³¨é‡Šè¡Œ
        try:
            # å…ˆè¯»å–ç¬¬ä¸€è¡Œçœ‹æ˜¯å¦æœ‰æ³¨é‡Š
            with open(csv_file, 'r') as f:
                first_line = f.readline().strip()

            if first_line.startswith('#'):
                df = pd.read_csv(csv_file, skiprows=1)
            else:
                df = pd.read_csv(csv_file)
        except Exception as e:
            print(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
            raise ValueError(f"æ— æ³•è¯»å–æ–‡ä»¶ {csv_file}")

        # éªŒè¯å¿…éœ€çš„åˆ—æ˜¯å¦å­˜åœ¨
        required_coordinate_columns = ['X', 'Y']
        missing_coord_columns = [col for col in required_coordinate_columns if col not in df.columns]
        if missing_coord_columns:
            raise ValueError(f"æ–‡ä»¶ {csv_file} ç¼ºå°‘å¿…éœ€çš„åæ ‡åˆ—: {missing_coord_columns}. å¯ç”¨åˆ—: {df.columns.tolist()}")

        # æŸ¥æ‰¾é¢‘ç‡å’Œåœºå€¼åˆ—
        columns = df.columns.tolist()
        freq_columns = [col for col in columns if col.startswith('freq_')]
        real_columns = [col for col in columns if col.startswith('Ez_real_')]
        imag_columns = [col for col in columns if col.startswith('Ez_imag_')]

        if not freq_columns:
            raise ValueError(f"æ–‡ä»¶ {csv_file} ä¸­æœªæ‰¾åˆ°é¢‘ç‡åˆ— (freq_1, freq_2ç­‰). å¯ç”¨åˆ—: {df.columns.tolist()}")
        if not real_columns:
            raise ValueError(f"æ–‡ä»¶ {csv_file} ä¸­æœªæ‰¾åˆ°å®éƒ¨åœºå€¼åˆ— (Ez_real_1, Ez_real_2ç­‰). å¯ç”¨åˆ—: {df.columns.tolist()}")
        if not imag_columns:
            raise ValueError(f"æ–‡ä»¶ {csv_file} ä¸­æœªæ‰¾åˆ°è™šéƒ¨åœºå€¼åˆ— (Ez_imag_1, Ez_imag_2ç­‰). å¯ç”¨åˆ—: {df.columns.tolist()}")

        # éªŒè¯é¢‘ç‡ç´¢å¼•çš„æœ‰æ•ˆæ€§
        if freq_idx >= len(freq_columns):
            print(f"è­¦å‘Šï¼šé¢‘ç‡ç´¢å¼• {freq_idx} è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªé¢‘ç‡ (ç´¢å¼• 0)")
            freq_idx = 0

        # éªŒè¯æ‰€æœ‰æ•°ç»„çš„é•¿åº¦æ˜¯å¦ä¸€è‡´
        if not (len(freq_columns) == len(real_columns) == len(imag_columns)):
            raise ValueError(f"æ–‡ä»¶ {csv_file} ä¸­é¢‘ç‡ã€å®éƒ¨ã€è™šéƒ¨åˆ—æ•°é‡ä¸ä¸€è‡´: "
                           f"é¢‘ç‡={len(freq_columns)}, å®éƒ¨={len(real_columns)}, è™šéƒ¨={len(imag_columns)}")

        # æå–åæ ‡ã€é¢‘ç‡å’Œåœºå€¼
        try:
            x = df['X'].values  # ä½¿ç”¨æ­£ç¡®çš„åˆ—å
            y = df['Y'].values

            # è°ƒè¯•ï¼šæ£€æŸ¥é¢‘ç‡åˆ—
            selected_freq_col = freq_columns[freq_idx]
            selected_real_col = real_columns[freq_idx]
            selected_imag_col = imag_columns[freq_idx]

            # éªŒè¯æ•°æ®ç±»å‹å’Œæ ¼å¼
            frequency_data = df[selected_freq_col]
            real_data = df[selected_real_col]
            imag_data = df[selected_imag_col]

            # æ£€æŸ¥æ˜¯å¦æœ‰NaNå€¼
            if frequency_data.isna().all():
                raise ValueError(f"é¢‘ç‡åˆ— {selected_freq_col} å…¨éƒ¨ä¸ºNaN")
            if real_data.isna().all():
                raise ValueError(f"å®éƒ¨åˆ— {selected_real_col} å…¨éƒ¨ä¸ºNaN")
            if imag_data.isna().all():
                raise ValueError(f"è™šéƒ¨åˆ— {selected_imag_col} å…¨éƒ¨ä¸ºNaN")

            # è·å–é¢‘ç‡å€¼ï¼ˆæ ‡é‡å€¼ï¼‰
            frequency = frequency_data.iloc[0]

            # æ£€æŸ¥é¢‘ç‡æ˜¯å¦ä¸ºæœ‰æ•ˆæ•°å€¼
            if pd.isna(frequency):
                raise ValueError(f"æ–‡ä»¶ {csv_file} ä¸­ {selected_freq_col} çš„ç¬¬ä¸€ä¸ªå€¼ä¸ºNaN")

            try:
                frequency = float(frequency)
            except (ValueError, TypeError) as e:
                raise ValueError(f"é¢‘ç‡å€¼ '{frequency}' æ— æ³•è½¬æ¢ä¸ºæµ®ç‚¹æ•°: {e}")

            # è·å–åœºå€¼æ•°ç»„
            real = real_data.values
            imag = imag_data.values

        except KeyError as e:
            print(f"æå–å­—æ®µå¤±è´¥ï¼Œæ–‡ä»¶ {csv_file}: {e}")
            print(f"å¯ç”¨åˆ—å: {df.columns.tolist()}")
            print(f"é¢‘ç‡åˆ—: {freq_columns}")
            print(f"å®éƒ¨åˆ—: {real_columns}")
            print(f"è™šéƒ¨åˆ—: {imag_columns}")
            raise ValueError(f"ç¼ºå°‘å¿…è¦çš„åˆ—: {e}")
        except ValueError as e:
            print(f"æ•°æ®è½¬æ¢å¤±è´¥ï¼Œæ–‡ä»¶ {csv_file}: {e}")
            raise e

        # åˆ›å»ºDataFrame
        df_processed = pd.DataFrame({
            'x': x,
            'y': y,
            'real': real,
            'imag': imag,
            'frequency': frequency
        })

        # ç§»é™¤NaNå€¼
        df_processed = df_processed.dropna()
        if len(df_processed) == 0:
            raise ValueError(f"æ–‡ä»¶ {csv_file} æ¸…ç†åæ— æœ‰æ•ˆæ•°æ®")

        total_points = len(df_processed)

        # æ­¥éª¤1ï¼šé€‰æ‹©æ¢é’ˆä½ç½®
        current_probe_count = self.probe_count
        if total_points < current_probe_count:
            # é™é»˜å¤„ç†æ¢é’ˆæ•°é‡è°ƒæ•´
            current_probe_count = total_points

        if self.fixed_probe_positions:
            # å›ºå®šæ¢é’ˆä½ç½®æ¨¡å¼ï¼šæ‰€æœ‰æ ·æœ¬ä½¿ç”¨ç›¸åŒçš„æ¢é’ˆä½ç½®
            cache_key = f"{csv_file}_{freq_idx}"

            if cache_key not in self.fixed_probe_cache:
                # ç¬¬ä¸€æ¬¡å¤„ç†è¿™ä¸ªæ–‡ä»¶/é¢‘ç‡ç»„åˆï¼Œç”Ÿæˆå›ºå®šçš„æ¢é’ˆä½ç½®
                print(f"ğŸ”’ ç”Ÿæˆå›ºå®šæ¢é’ˆä½ç½®: {Path(csv_file).name}, é¢‘ç‡{freq_idx}GHz")
                rng = np.random.RandomState(seed=hash(f"{csv_file}_{freq_idx}_FIXED_PROBES") % (2**32))
                probe_indices = rng.choice(total_points, current_probe_count, replace=False)
                self.fixed_probe_cache[cache_key] = probe_indices
                print(f"âœ… å›ºå®šæ¢é’ˆä½ç½®å·²ç¼“å­˜ï¼Œæ¢é’ˆæ•°é‡: {len(probe_indices)}")
            else:
                # ä½¿ç”¨ç¼“å­˜çš„å›ºå®šæ¢é’ˆä½ç½®
                probe_indices = self.fixed_probe_cache[cache_key]
                # é™é»˜æ¨¡å¼ï¼Œä¸éœ€è¦æ¯æ¬¡éƒ½æ‰“å°
                if sample_idx == 0:  # åªåœ¨ç¬¬ä¸€æ¬¡æ‰“å°ï¼Œé¿å…æ—¥å¿—è¿‡å¤š
                    print(f"ğŸ“ ä½¿ç”¨ç¼“å­˜çš„å›ºå®šæ¢é’ˆä½ç½®: {Path(csv_file).name}, é¢‘ç‡{freq_idx}GHz, æ¢é’ˆæ•°: {len(probe_indices)}")
        else:
            # éšæœºæ¢é’ˆä½ç½®æ¨¡å¼ï¼šæ¯ä¸ªsample_idxä½¿ç”¨ä¸åŒçš„æ¢é’ˆä½ç½®
            rng = np.random.RandomState(seed=hash(f"{csv_file}_{freq_idx}_{sample_idx}") % (2**32))
            probe_indices = rng.choice(total_points, current_probe_count, replace=False)
            if sample_idx == 0:  # åªåœ¨ç¬¬ä¸€æ¬¡æ‰“å°ï¼Œé¿å…æ—¥å¿—è¿‡å¤š
                print(f"ğŸ² ç”Ÿæˆéšæœºæ¢é’ˆä½ç½®: {Path(csv_file).name}, é¢‘ç‡{freq_idx}GHz, sample_idx:{sample_idx}, æ¢é’ˆæ•°: {len(probe_indices)}")

        # æ­¥éª¤2ï¼šåŸºäºé€‰ä¸­çš„æ¢é’ˆæ„å»ºå‡¸è¾¹ç•Œ
        all_coords = df_processed[['x', 'y']].values
        probe_coords = all_coords[probe_indices]  # æ¢é’ˆä½ç½®

        # åŸºäºæ¢é’ˆä½ç½®æ„å»ºå‡¸è¾¹ç•Œ - æ”¹è¿›ç‰ˆæœ¬ï¼šç¡®ä¿æ¢é’ˆç‚¹å§‹ç»ˆåŒ…å«åœ¨å†…
        try:
            hull = ConvexHull(probe_coords)
            hull_vertices = hull.vertices

            # ä½¿ç”¨matplotlib.pathæ¥åˆ¤æ–­ç‚¹æ˜¯å¦åœ¨æ¢é’ˆæ„æˆçš„å‡¸è¾¹ç•Œå†…
            from matplotlib.path import Path as MatplotlibPath
            hull_path = MatplotlibPath(probe_coords[hull_vertices])

            # å…³é”®ä¿®å¤1: ä½¿ç”¨æ›´å¤§çš„radiusç¡®ä¿è¾¹ç•Œç‚¹è¢«åŒ…å«
            interior_mask = hull_path.contains_points(all_coords, radius=1e-6)  # å¢å¤§radius

            # å…³é”®ä¿®å¤2: å¼ºåˆ¶åŒ…å«æ‰€æœ‰æ¢é’ˆä½ç½®ï¼Œç¡®ä¿æ¢é’ˆä¸è¢«å‡¸åŒ…ç­›é€‰æ‰
            # åˆ›å»ºæœ€ç»ˆçš„interior_maskï¼šå‡¸åŒ…å†…ç‚¹ + æ‰€æœ‰æ¢é’ˆç‚¹
            probe_included_mask = np.zeros(len(all_coords), dtype=bool)
            for probe_idx in probe_indices:
                probe_included_mask[probe_idx] = True  # å¼ºåˆ¶åŒ…å«æ‰€æœ‰æ¢é’ˆ

            # åˆå¹¶ï¼šå‡¸åŒ…å†…ç‚¹ âˆª æ¢é’ˆç‚¹
            interior_mask = interior_mask | probe_included_mask

            # æ­¥éª¤3ï¼šæ„å»ºåŒ…å«æ¢é’ˆçš„å®Œæ•´æ•°æ®é›†
            df_interior = df_processed[interior_mask].copy()
            interior_coords = all_coords[interior_mask]
            interior_fields = df_processed[['real', 'imag']].values[interior_mask]

            if len(df_interior) == 0:
                print(f"è­¦å‘Šï¼šæ„å‹ {Path(csv_file).name} é¢‘ç‡{freq_idx} ç­›é€‰åæ— æ•°æ®ç‚¹ï¼Œä½¿ç”¨æ‰€æœ‰æ•°æ®")
                df_interior = df_processed.copy()
                interior_coords = all_coords
                interior_fields = df_processed[['real', 'imag']].values
                interior_mask = np.ones(len(all_coords), dtype=bool)

        except Exception as e:
            print(f"æ„å‹ {Path(csv_file).name} é¢‘ç‡{freq_idx} æ¢é’ˆå‡¸è¾¹ç•Œè®¡ç®—å¤±è´¥: {e}ï¼Œä½¿ç”¨æ‰€æœ‰æ•°æ®ç‚¹")
            df_interior = df_processed.copy()
            interior_coords = all_coords
            interior_fields = df_processed[['real', 'imag']].values
            interior_mask = np.ones(len(all_coords), dtype=bool)

        # å…³é”®ä¿®å¤3: ç›´æ¥æ„å»ºæ¢é’ˆmaskï¼Œé¿å…å¤æ‚çš„åæ ‡åŒ¹é…
        # ç”±äºæˆ‘ä»¬å¼ºåˆ¶åŒ…å«äº†æ¢é’ˆç‚¹ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨åŸå§‹æ¢é’ˆç´¢å¼•
        probe_mask = np.zeros(len(df_interior), dtype=bool)

        # å»ºç«‹ä»åŸå§‹ç´¢å¼•åˆ°interiorç´¢å¼•çš„æ˜ å°„
        # è¿™æ ·å¯ä»¥ç›´æ¥æ‰¾åˆ°æ¢é’ˆåœ¨interioræ•°æ®ä¸­çš„ä½ç½®
        original_to_interior = {}
        interior_counter = 0

        for original_idx in range(len(all_coords)):
            if interior_mask[original_idx]:
                original_to_interior[original_idx] = interior_counter
                interior_counter += 1

        # ä½¿ç”¨æ˜ å°„ç›´æ¥è®¾ç½®æ¢é’ˆmask - 100%å‡†ç¡®ï¼
        for probe_idx in probe_indices:
            if probe_idx in original_to_interior:
                interior_idx = original_to_interior[probe_idx]
                probe_mask[interior_idx] = True
            else:
                print(f"é”™è¯¯ï¼šæ¢é’ˆç´¢å¼•{probe_idx}æœªåœ¨æ˜ å°„ä¸­æ‰¾åˆ°ï¼Œè¿™ä¸åº”è¯¥å‘ç”Ÿ")

        found_probes = np.sum(probe_mask)
        expected_probes = len(probe_indices)

        if found_probes != expected_probes:
            # æœ€åçš„å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿è‡³å°‘æœ‰æ¢é’ˆä½ç½®
            if found_probes == 0:
                probe_mask[:min(expected_probes, len(probe_mask))] = True

        # æ­¥éª¤4ï¼šæ„å»ºå•Branchè®­ç»ƒæ•°æ® - äº¤é”™æ ¼å¼åŒ…å«å®éƒ¨å’Œè™šéƒ¨
        # åˆ›å»ºé¢‘ç‡æ•°ç»„ï¼Œå¹¶åº”ç”¨é¢‘ç‡ç¼©æ”¾ï¼ˆé™¤ä»¥1GHzåŸºå‡†ï¼‰
        if self.cfg.data.enable_frequency_scaling:
            frequency_scaled = frequency / self.cfg.data.frequency_scale_factor  # å°†é¢‘ç‡è½¬æ¢ä¸ºä»¥1GHzä¸ºåŸºå‡†çš„æ— é‡çº²å€¼
        else:
            frequency_scaled = frequency  # ä½¿ç”¨åŸå§‹é¢‘ç‡å€¼

        # probe_coords_only: æ¢é’ˆä½ç½®åæ ‡ [æ¢é’ˆæ•°, 2] = (x, y)
        # æ³¨æ„ï¼šæˆ‘ä»¬ç”µç£åœºæ•°æ®æ˜¯2Dçš„ï¼Œæ²¡æœ‰zåæ ‡
        probe_coords_only = probe_coords  # [æ¢é’ˆæ•°, 2] (x, y)

        # è·å–æ¢é’ˆä½ç½®çš„æµ‹é‡åœºå€¼
        probe_fields = df_processed[['real', 'imag']].values[probe_indices]  # [æ¢é’ˆæ•°, 2] (real, imag)
        probe_real_values = probe_fields[:, 0]  # [æ¢é’ˆæ•°] å®éƒ¨æµ‹é‡å€¼
        probe_imag_values = probe_fields[:, 1]  # [æ¢é’ˆæ•°] è™šéƒ¨æµ‹é‡å€¼

        # ç”Ÿæˆå•Branchè¾“å…¥ [æ¢é’ˆæ•°*4 + 1] = [x1,y1,r1,i1, x2,y2,r2,i2, ..., freq]
        branch_input = self._create_single_branch_input(
            probe_coords_only, probe_real_values, probe_imag_values, frequency_scaled
        )

        # trunk_input: å‡¸è¾¹ç•Œå†…æ‰€æœ‰ä½ç½®åæ ‡ [å†…ç‚¹æ•°, 3] = (x, y, frequency)
        # æ³¨æ„ï¼štrunkç½‘ç»œä½¿ç”¨2Dåæ ‡+é¢‘ç‡ï¼Œæ²¡æœ‰zåæ ‡
        # åº”ç”¨ç›¸åŒçš„é¢‘ç‡ç¼©æ”¾
        freq_array_interior = np.full((len(df_interior), 1), frequency_scaled)
        trunk_input = np.concatenate([interior_coords, freq_array_interior], axis=1)

        # target_output: å‡¸è¾¹ç•Œå†…æ‰€æœ‰åœºå€¼ [å†…ç‚¹æ•°, 2] = (real, imag)
        target_output = interior_fields

        # probe_coords_3d: æ¢é’ˆåæ ‡ï¼ˆæ‰©å±•ä¸º3Dï¼Œz=0ï¼‰ç”¨äºlossè®¡ç®—
        z_zeros = np.zeros((current_probe_count, 1))
        probe_coords_3d = np.concatenate([probe_coords_only, z_zeros], axis=1)

        # è¿”å›: å•branchè¾“å…¥, trunkè¾“å…¥, ç›®æ ‡è¾“å‡º, æ¢é’ˆmask, æ¢é’ˆåæ ‡
        return branch_input, trunk_input, target_output, probe_mask, probe_coords_3d

    def create_deeponet_dataset(self, samples_list: List[Dict[str, Any]],
                               train_ratio: float = 0.8) -> Tuple:
        """åˆ›å»ºDeepONetæ ¼å¼æ•°æ®é›†"""
        # éšæœºæ‰“ä¹±æ ·æœ¬
        np.random.shuffle(samples_list)

        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        split_idx = int(len(samples_list) * train_ratio)
        train_samples = samples_list[:split_idx]
        test_samples = samples_list[split_idx:]

        # å‡†å¤‡è®­ç»ƒæ•°æ®
        return self._prepare_batch_data(train_samples, test_samples)

    def _prepare_batch_data(self, train_samples: List[Dict],
                           test_samples: List[Dict]) -> Tuple:
        """å‡†å¤‡æ‰¹æ¬¡æ•°æ® - å¤„ç†å¯å˜é•¿åº¦æ•°æ®ï¼ˆå•Branchæ ¼å¼ï¼‰"""
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        branch_train_list = []  # å•Branchè¾“å…¥
        trunk_train_list = []
        y_train_list = []
        masks_train_list = []
        probe_coords_train_list = []  # æ¢é’ˆåæ ‡

        print("å‡†å¤‡è®­ç»ƒæ•°æ®...")
        for i, sample in enumerate(train_samples):
            try:
                # ä½¿ç”¨æ ·æœ¬ä¸­çš„é¢‘ç‡ç´¢å¼•
                freq_idx = sample.get('freq_idx', 0)
                branch_input, trunk_input, target_output, mask, probe_coords = self.prepare_single_sample(sample['file'], freq_idx=freq_idx)
                branch_train_list.append(branch_input)
                trunk_train_list.append(trunk_input)
                y_train_list.append(target_output)
                masks_train_list.append(mask)
                probe_coords_train_list.append(probe_coords)

                print(f"å·²å¤„ç† {i + 1}/{len(train_samples)} ä¸ªè®­ç»ƒæ ·æœ¬", end='\r')

            except ValueError as e:
                print(f"è·³è¿‡è®­ç»ƒæ ·æœ¬ {sample.get('source_file', sample['file'])} (é¢‘ç‡ç´¢å¼• {freq_idx}): {e}")
                # è·³è¿‡æ— æ•ˆæ–‡ä»¶ï¼Œç»§ç»­å¤„ç†å…¶ä»–æ–‡ä»¶
                continue
            except Exception as e:
                print(f"å¤„ç†è®­ç»ƒæ ·æœ¬ {sample.get('source_file', sample['file'])} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
                # è·³è¿‡é”™è¯¯æ–‡ä»¶ï¼Œç»§ç»­å¤„ç†
                continue

        # å®Œæˆåæ¢è¡Œ
        print()  # æ¢è¡Œ
        print(f"è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ: {len(branch_train_list)} ä¸ªæœ‰æ•ˆæ ·æœ¬")

        # å‡†å¤‡æµ‹è¯•æ•°æ®
        branch_test_list = []  # å•Branchè¾“å…¥
        trunk_test_list = []
        y_test_list = []
        masks_test_list = []
        probe_coords_test_list = []  # æ¢é’ˆåæ ‡

        print("å‡†å¤‡æµ‹è¯•æ•°æ®...")
        for i, sample in enumerate(test_samples):
            try:
                # ä½¿ç”¨æ ·æœ¬ä¸­çš„é¢‘ç‡ç´¢å¼•
                freq_idx = sample.get('freq_idx', 0)
                branch_input, trunk_input, target_output, mask, probe_coords = self.prepare_single_sample(sample['file'], freq_idx=freq_idx)
                branch_test_list.append(branch_input)
                trunk_test_list.append(trunk_input)
                y_test_list.append(target_output)
                masks_test_list.append(mask)
                probe_coords_test_list.append(probe_coords)

                print(f"å·²å¤„ç† {i + 1}/{len(test_samples)} ä¸ªæµ‹è¯•æ ·æœ¬", end='\r')

            except ValueError as e:
                print(f"è·³è¿‡æµ‹è¯•æ ·æœ¬ {sample.get('source_file', sample['file'])} (é¢‘ç‡ç´¢å¼• {freq_idx}): {e}")
                # è·³è¿‡æ— æ•ˆæ–‡ä»¶ï¼Œç»§ç»­å¤„ç†å…¶ä»–æ–‡ä»¶
                continue
            except Exception as e:
                print(f"å¤„ç†æµ‹è¯•æ ·æœ¬ {sample.get('source_file', sample['file'])} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
                # è·³è¿‡é”™è¯¯æ–‡ä»¶ï¼Œç»§ç»­å¤„ç†
                continue

        # å®Œæˆåæ¢è¡Œ
        print()  # æ¢è¡Œ
        print(f"æµ‹è¯•æ•°æ®å‡†å¤‡å®Œæˆ: {len(branch_test_list)} ä¸ªæœ‰æ•ˆæ ·æœ¬")

        # ä¸è¦ç›´æ¥åˆå¹¶ä¸ºnumpyæ•°ç»„ï¼Œè¿”å›åˆ—è¡¨è®©è®­ç»ƒå™¨å¤„ç†å¯å˜é•¿åº¦
        print(f"è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ: {len(branch_train_list)} ä¸ªæ ·æœ¬")
        print(f"æµ‹è¯•æ•°æ®å‡†å¤‡å®Œæˆ: {len(branch_test_list)} ä¸ªæ ·æœ¬")

        # è¿”å›å•Branchæ ¼å¼æ•°æ®
        return (branch_train_list, trunk_train_list, y_train_list, masks_train_list, probe_coords_train_list,
                branch_test_list, trunk_test_list, y_test_list, masks_test_list, probe_coords_test_list)

    def get_data_statistics(self, samples_list: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        if not samples_list:
            return {}

        frequencies = [sample['frequency'] for sample in samples_list]
        file_sizes = [sample['size'] for sample in samples_list]

        stats = {
            'total_samples': len(samples_list),
            'frequency_range': (min(frequencies) if frequencies else 0, max(frequencies) if frequencies else 0),
            'mean_frequency': np.mean(frequencies) if frequencies else 0,
            'std_frequency': np.std(frequencies) if frequencies else 0,
            'total_size_mb': sum(file_sizes) / (1024 * 1024),
            'avg_size_mb': np.mean(file_sizes) / (1024 * 1024) if file_sizes else 0
        }

        return stats


class OptimizedDataLoader:
    """å†…å­˜ä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨"""

    def __init__(self, cfg: Config):
        self.cfg = cfg
        self.batch_size = cfg.training.batch_size

    def load_data_generator(self, sample_files: List[Dict], mode: str = 'train') -> Generator[Dict, None, None]:
        """ç”Ÿæˆå™¨æ¨¡å¼åŠ è½½æ•°æ®ï¼Œå‡å°‘å†…å­˜å ç”¨"""
        dataset = MaskedDeepONetDataset(self.cfg)

        while True:
            # éšæœºæ‰“ä¹±
            np.random.shuffle(sample_files)

            # åˆ†æ‰¹å¤„ç†
            for i in range(0, len(sample_files), self.batch_size):
                batch_files = sample_files[i:i + self.batch_size]

                branch_real_batch = []
                branch_imag_batch = []
                trunk_batch = []
                y_batch = []
                mask_batch = []

                for file_dict in batch_files:
                    try:
                        branch_real_input, branch_imag_input, trunk_input, target_output, mask = dataset.prepare_single_sample(file_dict['file'], freq_idx=0)
                        branch_real_batch.append(branch_real_input)
                        branch_imag_batch.append(branch_imag_input)
                        trunk_batch.append(trunk_input)
                        y_batch.append(target_output)
                        mask_batch.append(mask)
                    except Exception as e:
                        print(f"åŠ è½½æ–‡ä»¶ {file_dict['file']} æ—¶å‡ºé”™: {e}")
                        continue

                if branch_real_batch:  # ç¡®ä¿æœ‰æœ‰æ•ˆæ•°æ®
                    yield {
                        'branch_real': np.array(branch_real_batch),
                        'branch_imag': np.array(branch_imag_batch),
                        'trunk': np.array(trunk_batch),
                        'y': np.array(y_batch),
                        'masks': mask_batch
                    }

                # æ¸…ç†ä¸´æ—¶å˜é‡
                del branch_real_batch, branch_imag_batch, trunk_batch, y_batch, mask_batch